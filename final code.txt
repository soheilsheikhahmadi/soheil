import pandas as pd
import os
import matplotlib.pyplot as plt
import seaborn as sns
import numpy as np
from sklearn.preprocessing import StandardScaler, OneHotEncoder
from sklearn.compose import ColumnTransformer
from sklearn.model_selection import train_test_split, KFold, GridSearchCV
from sklearn.metrics import mean_squared_error, r2_score, mean_absolute_error, explained_variance_score
from sklearn.linear_model import Ridge, Lasso, ElasticNet
from sklearn.metrics import make_scorer
from sklearn.neural_network import MLPRegressor
from sklearn.pipeline import Pipeline
from xgboost import XGBRegressor
from scipy import stats

sns.set(style="whitegrid")

file_path = r'C:\Users\ACER\Desktop\behine\Energy_consumption_dataset.csv'

if os.path.isfile(file_path):
    df = pd.read_csv(file_path)

    numeric_columns = df.select_dtypes(include=['float64', 'int64']).columns
    df[numeric_columns] = df[numeric_columns].fillna(df[numeric_columns].mean())

    X = df.drop(columns=["EnergyConsumption"])
    y = df["EnergyConsumption"]

    categorical_features = ["DayOfWeek", "Holiday", "HVACUsage", "LightingUsage"]
    numerical_features = ["Month", "Hour", "Temperature", "Humidity", "SquareFootage", "Occupancy", "RenewableEnergy"]

    categorical_transformer = OneHotEncoder(drop="first", sparse_output=False)
    numerical_transformer = StandardScaler()

    preprocessor = ColumnTransformer(
        transformers=[
            ("num", numerical_transformer, numerical_features),
            ("cat", categorical_transformer, categorical_features),
        ]
    )

    X_processed = preprocessor.fit_transform(X)

    X_train, X_test, y_train, y_test = train_test_split(X_processed, y, test_size=0.2, random_state=42)

    plt.figure(figsize=(15, 5))

    plt.subplot(1, 2, 1)
    df.groupby('Month')['EnergyConsumption'].mean().plot(kind='bar', color='#5A9BD5')
    plt.title('Average Energy Consumption by Month')
    plt.xlabel('Month')
    plt.ylabel('Average Energy Consumption')

    plt.subplot(1, 2, 2)
    df.groupby('Hour')['EnergyConsumption'].mean().plot(kind='line', color='#388E3C')
    plt.title('Average Energy Consumption by Hour')
    plt.xlabel('Hour')
    plt.ylabel('Average Energy Consumption')

    plt.tight_layout()
    plt.show()

    fig, axes = plt.subplots(2, 2, figsize=(15, 10))

    sns.boxplot(x='DayOfWeek', y='EnergyConsumption', data=df, ax=axes[0, 0], color='#8D6E63')
    axes[0, 0].set_title('Energy Consumption by Day of Week')

    sns.boxplot(x='Holiday', y='EnergyConsumption', data=df, ax=axes[0, 1], color='#FBC02D')
    axes[0, 1].set_title('Energy Consumption by Holiday')

    sns.boxplot(x='HVACUsage', y='EnergyConsumption', data=df, ax=axes[1, 0], color='#C62828')
    axes[1, 0].set_title('Energy Consumption by HVAC Usage')

    sns.boxplot(x='LightingUsage', y='EnergyConsumption', data=df, ax=axes[1, 1], color='#FBC02D')
    axes[1, 1].set_title('Energy Consumption by Lighting Usage')

    plt.tight_layout()
    plt.show()

    numerical_features = ['Temperature', 'Humidity', 'SquareFootage', 'Occupancy']
    fig, axes = plt.subplots(2, 2, figsize=(15, 10))
    axes = axes.ravel()

    for idx, feature in enumerate(numerical_features):
        sns.scatterplot(data=df, x=feature, y='EnergyConsumption', alpha=0.5, ax=axes[idx], color='#5A9BD5')
        axes[idx].set_title(f'Energy Consumption vs {feature}')

    plt.tight_layout()
    plt.show()

    correlation_matrix = df.select_dtypes(include=[np.number]).corr()
    plt.figure(figsize=(12, 8))
    sns.heatmap(correlation_matrix, annot=True, cmap='Blues', center=0, annot_kws={"size": 12, "weight": 'bold', 'color': 'black'})
    plt.title('Correlation Matrix of Numerical Features', fontsize=16, fontweight='bold')
    plt.xticks(fontsize=12, fontweight='bold')
    plt.yticks(fontsize=12, fontweight='bold')
    output_path = 'correlation_matrix_high_quality.png'
    plt.savefig(output_path, dpi=300)
    plt.tight_layout()
    plt.show()

    class ModelTrainer:
        def __init__(self, random_state=42):
            self.random_state = random_state
            self.cv = KFold(n_splits=5, shuffle=True, random_state=random_state)
            self.scoring = {
                'neg_mean_squared_error': make_scorer(mean_squared_error, greater_is_better=False),
                'r2': make_scorer(r2_score)
            }

        def get_param_grid(self):
            return {
                'MLP': {
                    'model': MLPRegressor(max_iter=1000, random_state=self.random_state),
                    'params': {
                        'hidden_layer_sizes': [(50,), (100,), (100, 50)],
                        'activation': ['relu', 'tanh'],
                        'solver': ['adam'],
                        'alpha': [0.0001, 0.001, 0.01],
                        'learning_rate': ['constant', 'adaptive'],
                    }
                },
                'Ridge': {
                    'model': Ridge(random_state=self.random_state),
                    'params': {
                        'alpha': [0.1, 1.0, 10.0],
                        'solver': ['auto', 'lsqr']
                    }
                },
                'Lasso': {
                    'model': Lasso(random_state=self.random_state),
                    'params': {
                        'alpha': [0.1, 0.5, 1.0, 10.0]
                    }
                },
                'ElasticNet': {
                    'model': ElasticNet(random_state=self.random_state),
                    'params': {
                        'alpha': [0.1, 0.5, 1.0, 10.0],
                        'l1_ratio': [0.2, 0.5, 0.8, 1.0]
                    }
                },
                'XGBoost': {
                    'model': XGBRegressor(random_state=self.random_state),
                    'params': {
                        'n_estimators': [100, 200],
                        'max_depth': [3, 5],
                        'learning_rate': [0.01, 0.1],
                        'subsample': [0.8, 1.0],
                        'colsample_bytree': [0.8, 1.0]
                    }
                }
            }

        def train_and_evaluate(self, X, y):
            param_grids = self.get_param_grid()
            best_models = {}

            for name, config in param_grids.items():
                grid_search = GridSearchCV(
                    config['model'],
                    config['params'],
                    cv=self.cv,
                    scoring=self.scoring,
                    refit='r2',
                    n_jobs=-1,
                    verbose=1
                )
                grid_search.fit(X, y)
                best_models[name] = {
                    'best_params': grid_search.best_params_,
                    'best_score': grid_search.best_score_,
                    'best_model': grid_search.best_estimator_
                }

            return best_models

    trainer = ModelTrainer()
    best_models = trainer.train_and_evaluate(X_train, y_train)

    class ModelEvaluator:
        def evaluate_model(self, model, X, y):
            predictions = model.predict(X)
            metrics = {
                'R2 Score': model.score(X, y),
                'MSE': mean_squared_error(y, predictions),
                'RMSE': np.sqrt(mean_squared_error(y, predictions)),
                'MAE': mean_absolute_error(y, predictions),
                'Explained Variance': explained_variance_score(y, predictions),
            }
            return metrics

        def evaluate_all_models(self, best_models, X, y):
            evaluation_results = []

            for name, results in best_models.items():
                metrics = self.evaluate_model(results['best_model'], X, y)
                metrics['Model'] = name
                evaluation_results.append(metrics)

            return pd.DataFrame(evaluation_results)

        def plot_residuals(self, model, X, y, title="Residuals Analysis"):
            predictions = model.predict(X)
            residuals = y - predictions

            plt.figure(figsize=(10, 5))
            sns.histplot(residuals, kde=True, bins=30, color='blue')
            plt.title(f"{title} - Residuals Distribution")
            plt.xlabel("Residuals")
            plt.ylabel("Frequency")
            plt.show()

            plt.figure(figsize=(10, 5))
            plt.scatter(predictions, residuals, alpha=0.5, color='red')
            plt.axhline(0, linestyle='--', color='black')
            plt.title(f"{title} - Residuals vs Predictions")
            plt.xlabel("Predicted Values")
            plt.ylabel("Residuals")
            plt.show()

            plt.figure(figsize=(10, 5))
            stats.probplot(residuals, dist="norm", plot=plt)
            plt.title(f"{title} - Q-Q Plot")
            plt.show()

            plt.figure(figsize=(10, 5))
            plt.scatter(np.arange(len(residuals)), residuals, alpha=0.5, color='purple')
            plt.axhline(0, linestyle='--', color='black')
            plt.title(f"{title} - Residuals Scatter Plot")
            plt.xlabel("Index")
            plt.ylabel("Residuals")
            plt.show()

    evaluator = ModelEvaluator()
    evaluation_results = evaluator.evaluate_all_models(best_models, X_processed, y)
    print("Model Evaluation Results:")
    print(evaluation_results)

    for model_name, model_info in best_models.items():
        evaluator.plot_residuals(model_info['best_model'], X_processed, y, title=f"Residuals Analysis for {model_name}")

    model_metrics = {
        "Model": [],
        "R2 Score": [],
        "MSE": [],
        "RMSE": [],
        "MAE": [],
    }

    for model_name, model_info in best_models.items():
        model = model_info['best_model']
        metrics = evaluator.evaluate_model(model, X_processed, y)
        model_metrics["Model"].append(model_name)
        model_metrics["R2 Score"].append(metrics['R2 Score'])
        model_metrics["MSE"].append(metrics['MSE'])
        model_metrics["RMSE"].append(metrics['RMSE'])
        model_metrics["MAE"].append(metrics['MAE'])

    metrics_df = pd.DataFrame(model_metrics)

    fig, axes = plt.subplots(2, 2, figsize=(15, 10))

    axes[0, 0].bar(metrics_df["Model"], metrics_df["R2 Score"], color='#5A9BD5')
    axes[0, 0].set_title('R2 Score Comparison')
    axes[0, 0].set_ylabel('R2 Score')

    axes[0, 1].bar(metrics_df["Model"], metrics_df["MSE"], color='#388E3C')
    axes[0, 1].set_title('MSE Comparison')
    axes[0, 1].set_ylabel('MSE')

    axes[1, 0].bar(metrics_df["Model"], metrics_df["RMSE"], color='#8D6E63')
    axes[1, 0].set_title('RMSE Comparison')
    axes[1, 0].set_ylabel('RMSE')

    axes[1, 1].bar(metrics_df["Model"], metrics_df["MAE"], color='#FBC02D')
    axes[1, 1].set_title('MAE Comparison')
    axes[1, 1].set_ylabel('MAE')

    plt.tight_layout()
    plt.show()

else:
    print("File does not exist, please check the path again.")
